{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG\n",
    "\n",
    "1. Data Ingestion\n",
    "2. Chunking\n",
    "3. embedding\n",
    "4. semantic search\n",
    "5. response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import ollama\n",
    "from ollama import chat\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    mypdf = pymupdf.open(pdf_path)\n",
    "    all_text = ''\n",
    "\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]\n",
    "        text = page.get_text(\"text\")\n",
    "        all_text += text\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        chunks.append(text[i:i+n])\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 7\n",
      "\n",
      "First text chunk:\n",
      "Mahikshit Kurapati\n",
      "+1 5717740349 | mahikshitkurapati@gmail.com | linkedin.com/in/mahikshitkurapati | mkurapati.vercel.app | github.com/Archonz-crazy\n",
      "PROFESSIONAL SUMMARY\n",
      "Solution-oriented Machine Learning Engineer with a background in Artificial Intelligence with 2+ years of experience building\n",
      "enterprise-level RAG models.\n",
      "Specialties include: designing machine learning platforms, data pipeline optimization, improving\n",
      "operational efficiency, solving ML problems end-to-end, ML/AI lifecycle management, applied machine learning solutions.\n",
      "EXPERIENCE\n",
      "AI Engineer | NForce One | Virginia, USA\n",
      "October 2024 - present\n",
      "• Collaborated with teams from Accenture to integrate legacy systems like Siebel and Prism with AI agents using Python,\n",
      "LangChain, GPT-4o, and Azure ML Studio. Enhanced customer management workflows and cut costs by 60%.\n",
      "• Engineered data pipelines using pgAdmin, retrieving and analyzing the data, ensuring 4x faster generation of business\n",
      "reports and Tableau dashboards to visualiz\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"/Users/mahikshitk/Downloads/Mahikshit_Kurapati_resume (6).pdf\"\n",
    "\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "text_chunks = chunk_text(extracted_text, 1000, 200)\n",
    "\n",
    "print(\"Number of text chunks:\", len(text_chunks))\n",
    "\n",
    "print(\"\\nFirst text chunk:\")\n",
    "print(text_chunks[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, model=\"nomic-embed-text:latest\"):\n",
    "    response = ollama.embed(\n",
    "        model=model,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "response = create_embeddings(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, text_chunks, embeddings, k=5):\n",
    "\n",
    "    query_embedding = create_embeddings(query)\n",
    "    similarity_scores = []\n",
    "    for i, chunk_embedding in enumerate(embeddings):\n",
    "        similarity_score = cosine_similarity(query_embedding.embeddings, chunk_embedding)\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_indices = [index for index, _ in similarity_scores[:k]]\n",
    "\n",
    "    return [text_chunks[index] for index in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is Mahikshit's first job?\n",
      "Context 1:\n",
      "Mahikshit Kurapati\n",
      "+1 5717740349 | mahikshitkurapati@gmail.com | linkedin.com/in/mahikshitkurapati | mkurapati.vercel.app | github.com/Archonz-crazy\n",
      "PROFESSIONAL SUMMARY\n",
      "Solution-oriented Machine Learning Engineer with a background in Artificial Intelligence with 2+ years of experience building\n",
      "enterprise-level RAG models.\n",
      "Specialties include: designing machine learning platforms, data pipeline optimization, improving\n",
      "operational efficiency, solving ML problems end-to-end, ML/AI lifecycle management, applied machine learning solutions.\n",
      "EXPERIENCE\n",
      "AI Engineer | NForce One | Virginia, USA\n",
      "October 2024 - present\n",
      "• Collaborated with teams from Accenture to integrate legacy systems like Siebel and Prism with AI agents using Python,\n",
      "LangChain, GPT-4o, and Azure ML Studio. Enhanced customer management workflows and cut costs by 60%.\n",
      "• Engineered data pipelines using pgAdmin, retrieving and analyzing the data, ensuring 4x faster generation of business\n",
      "reports and Tableau dashboards to visualiz\n",
      "=====================\n",
      "Context 2:\n",
      "hington University\n",
      "August 2022 - May 2024\n",
      "Bachelors in Computer Science(CS) | Jawaharlal Nehru Technological University\n",
      "June 2018 - May 2022\n",
      "SKILLS\n",
      "Languages: Python, R, SQL, JavaScript, TypeScript, Rust, bash\n",
      "Frameworks: Cloudera, React.js, Node.js, Computer Vision, Flask, Hive, CUDA, SQL Server, Hadoop, Big Data, Kafka, MATLAB\n",
      "Developer Tools: PostgreSQL, Azure ML Studio, Amazon Web Services, Kubeflow, MongoDB, GraphQL, Git, MySQL, Docker,\n",
      "Power BI, Tableau\n",
      "Operating Systems: Windows, MacOS, Linux, Unix\n",
      "Libraries: NumPy, PySpark, Pandas, Keras, SciPy, TensorFlow, NLTK, PyTorch, Scikit-learn, Langchain, Matplotlib, Seaborn\n",
      "Relevant skills: MLOps, Reinforcement Learning, Cloud Computing, Natural Language Processing, Computer Engineering, Appli-\n",
      "cation Development, Evaluation metrics, Software Development Lifecycle, Software Architecture, Statistics, CI/CD pipelines, ETL,\n",
      "Data Manipulation, Data Privacy, Amazon Bedrock, System Design, Agile methodologies, Distributed Systems, Model fine\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Mahikshit's first job?\"\n",
    "\n",
    "top_chunks = semantic_search(query, text_chunks, response.embeddings, k=2)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"Context {i+1}:\\n{chunk}\\n=====================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "Mahikshit Kurapati\n",
      "+1 5717740349 | mahikshitkurapati@gmail.com | linkedin.com/in/mahikshitkurapati | mkurapati.vercel.app | github.com/Archonz-crazy\n",
      "PROFESSIONAL SUMMARY\n",
      "Solution-oriented Machine Learning Engineer with a background in Artificial Intelligence with 2+ years of experience building\n",
      "enterprise-level RAG models.\n",
      "Specialties include: designing machine learning platforms, data pipeline optimization, improving\n",
      "operational efficiency, solving ML problems end-to-end, ML/AI lifecycle management, applied machine learning solutions.\n",
      "EXPERIENCE\n",
      "AI Engineer | NForce One | Virginia, USA\n",
      "October 2024 - present\n",
      "• Collaborated with teams from Accenture to integrate legacy systems like Siebel and Prism with AI agents using Python,\n",
      "LangChain, GPT-4o, and Azure ML Studio. Enhanced customer management workflows and cut costs by 60%.\n",
      "• Engineered data pipelines using pgAdmin, retrieving and analyzing the data, ensuring 4x faster generation of business\n",
      "reports and Tableau dashboards to visualiz\n",
      "=====================================\n",
      "\n",
      "Context 2:\n",
      "hington University\n",
      "August 2022 - May 2024\n",
      "Bachelors in Computer Science(CS) | Jawaharlal Nehru Technological University\n",
      "June 2018 - May 2022\n",
      "SKILLS\n",
      "Languages: Python, R, SQL, JavaScript, TypeScript, Rust, bash\n",
      "Frameworks: Cloudera, React.js, Node.js, Computer Vision, Flask, Hive, CUDA, SQL Server, Hadoop, Big Data, Kafka, MATLAB\n",
      "Developer Tools: PostgreSQL, Azure ML Studio, Amazon Web Services, Kubeflow, MongoDB, GraphQL, Git, MySQL, Docker,\n",
      "Power BI, Tableau\n",
      "Operating Systems: Windows, MacOS, Linux, Unix\n",
      "Libraries: NumPy, PySpark, Pandas, Keras, SciPy, TensorFlow, NLTK, PyTorch, Scikit-learn, Langchain, Matplotlib, Seaborn\n",
      "Relevant skills: MLOps, Reinforcement Learning, Cloud Computing, Natural Language Processing, Computer Engineering, Appli-\n",
      "cation Development, Evaluation metrics, Software Development Lifecycle, Software Architecture, Statistics, CI/CD pipelines, ETL,\n",
      "Data Manipulation, Data Privacy, Amazon Bedrock, System Design, Agile methodologies, Distributed Systems, Model fine\n",
      "=====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.\"\n",
    "\n",
    "def generate_response(system_prompt, user_message, model=\"deepseek-r1:8b\"):\n",
    "    response = chat(\n",
    "    model = model,\n",
    "    messages = [{'role': 'system', 'content': system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_message}])\n",
    "        \n",
    "    return response\n",
    "\n",
    "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
    "print(user_prompt)\n",
    "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
    "\n",
    "ai_response = generate_response(system_prompt, user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Based on the provided context, Mahikshit's first job isn't explicitly mentioned. The information available only details his current role as an AI Engineer at NForce One starting from October 2024.\n",
      "\n",
      "**Answer:** Mahikshit's first job is not explicitly mentioned in the given context.\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = re.sub(r'<think>.*?</think>', '', ai_response.message.content, flags=re.DOTALL)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The AI assistant's response was \"Mahikshit's first job\" and the correct answer is that Mahikshit's first job is not explicitly mentioned in the context provided.\n",
      "\n",
      "**Score: 0.5**\n",
      "\n",
      "Explanation:\n",
      "- The response correctly identifies that the first job isn't detailed, but it doesn't provide the true information as no specific job is mentioned.\n",
      "- It partially aligns with the expectation of providing an answer, though incomplete.\n"
     ]
    }
   ],
   "source": [
    "# Define the system prompt for the evaluation system\n",
    "evaluate_system_prompt = \"You are an intelligent evaluation system tasked with assessing the AI assistant's responses. If the AI assistant's response is very close to the true response, assign a score of 1. If the response is incorrect or unsatisfactory in relation to the true response, assign a score of 0. If the response is partially aligned with the true response, assign a score of 0.5.\"\n",
    "\n",
    "# Create the evaluation prompt by combining the user query, AI response, true response, and evaluation system prompt\n",
    "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response.message.content}\\nTrue Response: it is at Research Center Imarat\\n{evaluate_system_prompt}\"\n",
    "\n",
    "# Generate the evaluation response using the evaluation system prompt and evaluation prompt\n",
    "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
    "\n",
    "# Print the evaluation response\n",
    "cleaned_evaluation_text = re.sub(r'<think>.*?</think>', '', evaluation_response.message.content, flags=re.DOTALL)\n",
    "print(cleaned_evaluation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
